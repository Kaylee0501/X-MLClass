{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('../../datasets/AAPD/keyword_ext/update_labelspace_pke.txt', 'r')\n",
    "documents = file1.readlines()  \n",
    "predict_label_space = []\n",
    "for doc in documents:\n",
    "    predict_label_space.append(doc.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_label = []\n",
    "for i in range(len(df)):\n",
    "    s = df['Representation'][i]\n",
    "    if not s[1:-1].split(',')[0][1:-1] in rep_label:\n",
    "        rep_label.append(s[1:-1].split(',')[0][1:-1])\n",
    "predict_label_space = rep_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grocery_gourmet_food', 'meat_poultry', 'jerky', 'toys_games', 'games']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2 = open('../../datasets/Amazon-531/train/labels.txt', 'r')\n",
    "labels = file2.readlines()\n",
    "true_label = []\n",
    "for row in labels:\n",
    "    true_label.append(row.strip().split('\\t')[1])\n",
    "true_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Information Retrieval',\n",
       " 'Methodology',\n",
       " 'Quantum Physics',\n",
       " 'Information Theory',\n",
       " 'Applications']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2 = open('../../datasets/AAPD/true_labels.txt', 'r')\n",
    "labels = file2.readlines()\n",
    "label_dic = {}\n",
    "for row in labels:\n",
    "    key = row.strip().split(';')[0].split('.')[0]\n",
    "    #key + '.' + \n",
    "    label_dic[row.strip().split(';')[0]] = row.strip().split(';')[1][1:]\n",
    "true_label = []\n",
    "for key in label_dic:\n",
    "    if not label_dic[key] in true_label:\n",
    "        true_label.append(label_dic[key])\n",
    "true_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open('../../datasets/RCV1-V2/rcv1.topics.hier.orig.txt', 'r')\n",
    "labels = file2.readlines() \n",
    "true_label = []\n",
    "for row in labels[1:]:\n",
    "    new_label = row.strip().split('child-description: ')[1].lower()\n",
    "    true_label.append(new_label)\n",
    "true_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cocoa', 'sorghum', 'oat', 'barley', 'corn']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2 = open('../../datasets/Reuters-21578/train_label.txt', 'r')\n",
    "labels = file2.readlines()\n",
    "true_label = []\n",
    "for row in labels:\n",
    "    label_list = row.strip().split(' ')\n",
    "    for label in label_list:\n",
    "        if not label in true_label:\n",
    "            true_label.append(label)\n",
    "true_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: tensor([[0.4893]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "query_embedding = model.encode('teethers')\n",
    "passage_embedding = model.encode(['baby_dental_care'])\n",
    "\n",
    "print(\"Similarity:\", util.dot_score(query_embedding, passage_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_embedding = model.encode(predict_label_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = np.empty((0,len(predict_label_space)))\n",
    "for i in range(len(true_label)):\n",
    "    query_embedding = model.encode(true_label[i])\n",
    "    sim_matrix = np.append(sim_matrix, util.dot_score(query_embedding, passage_embedding).numpy(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 77)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list = []\n",
    "for i, sim_score in enumerate(sim_matrix):\n",
    "    rank_list = np.argsort(sim_score)[-40:]\n",
    "    cur_list = [true_label[i]]\n",
    "    for index in rank_list:\n",
    "        cur_list.append((sim_score[index], predict_label_space[index]))\n",
    "    if cur_list[-1][0] >= 0.6:\n",
    "        sim_list.append(cur_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Probability', 'probability'), 1.0],\n",
       " [('Optimization and Control', 'optimal control'), 0.8559101819992065],\n",
       " [('Numerical Analysis', 'extensive numerical investigations'),\n",
       "  0.8089126348495483],\n",
       " [('Statistics and Probability', 'probability'), 0.7721471786499023],\n",
       " [('Quantum Physics', 'quantum computations'), 0.7185327410697937],\n",
       " [('Performance', 'performance final comparisons'), 0.6822025179862976],\n",
       " [('Performance', 'efficiency'), 0.6781799793243408],\n",
       " [('Computational Complexity', 'sample complexity'), 0.6666020154953003],\n",
       " [('Optimization and Control', 'convex optimization'), 0.6558310985565186],\n",
       " [('Cryptography and Security', 'secure computation'), 0.633407473564148],\n",
       " [('Robotics', 'autonomous driving'), 0.6323422193527222],\n",
       " [('Social and Information Networks', 'networks'), 0.6213299632072449],\n",
       " [('Logic', 'finite logical implication'), 0.6042479276657104]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_list = []\n",
    "for line in sim_list:\n",
    "    true_label = line[0]\n",
    "    for row in line[1:]:\n",
    "        if row[0] >= 0.6:\n",
    "            pair_list.append([(true_label, row[1]), row[0]])\n",
    "sorted_pair_list = sorted(pair_list, key=lambda x: x[1], reverse = True)\n",
    "sorted_pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Probability', 'probability'), 1.0],\n",
       " [('Optimization and Control', 'optimal control'), 0.8559101819992065],\n",
       " [('Numerical Analysis', 'extensive numerical investigations'),\n",
       "  0.8089126348495483],\n",
       " [('Quantum Physics', 'quantum computations'), 0.7185327410697937],\n",
       " [('Performance', 'performance final comparisons'), 0.6822025179862976]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_pair_list = []\n",
    "while len(sorted_pair_list) > 0:\n",
    "    refine_pair_list.append([sorted_pair_list[0][0], sorted_pair_list[0][1]])\n",
    "    ground_truth = sorted_pair_list[0][0][0]\n",
    "    prediction = sorted_pair_list[0][0][1]\n",
    "    sorted_pair_list.pop(0)\n",
    "    delete_list = []\n",
    "    for row in sorted_pair_list:\n",
    "        if row[0][0] == ground_truth or row[0][1] == prediction:\n",
    "            delete_list.append(row)\n",
    "    for item in delete_list:\n",
    "        sorted_pair_list.remove(item)\n",
    "refine_pair_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(refine_pair_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20408163265306123"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multi-Label",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
